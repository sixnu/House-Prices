import numpy as np
import pandas as pd
import seaborn as sns
import missingno as msno
import matplotlib.pyplot as plt
from scipy import stats
import time
from scipy.stats import skew
#模型
import xgboost as xgb
from catboost import CatBoostRegressor
import lightgbm as lgb
#模型评估
from sklearn.metrics import roc_auc_score,mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score,train_test_split
import sklearn.preprocessing as preprocessing


#读取数据
data_train=pd.read_csv('.../train.csv')
data_test=pd.read_csv('.../test.csv')

#合并数据
data_train['type']='train'
data_test['type']='test'
data_all=pd.concat([data_train,data_test],axis=0,ignore_index=True,sort=False)

#查看头部数据
data_all.head(1).T

data_all.shape

#查看列名称
data_all.columns

#查看数据特征
data_all.info()

#查看相关性
corr = data_all.select_dtypes(include = ['float64', 'int64']).iloc[:,1:].corr()

print(corr['SalePrice'].sort_values())
print(corr['SalePrice'].abs().sort_values())

#查看数据类型
(data_all.dtypes=='object').value_counts()
data_all.dtypes.value_counts()

float_columns=data_all.dtypes[data_all.dtypes=='float64'].index

int_columns=data_all.dtypes[data_all.dtypes=='int64'].index

#查看数值分布
for i in int_columns[1:]:
    print (i)
    print(data_all[i].value_counts().sort_index())

object_columns=data_all.dtypes[data_all.dtypes=='object'].index


#热力图

#查看数据峰度
data_all.select_dtypes(include = ['float64', 'int64']).iloc[:,1:].skew().abs().sort_values()

skewed_feats = data_all[float_columns].apply(lambda x: skew(x.dropna())) #compute skewness
skewed_feats = skewed_feats[skewed_feats > 0.75]
skewed_feats = skewed_feats.index
data_all[skewed_feats] = np.log1p(data_all[skewed_feats])

skewed_feats = data_all[int_columns].apply(lambda x: skew(x.dropna())) #compute skewness
skewed_feats = skewed_feats[skewed_feats > 0.75]
skewed_feats = skewed_feats.index
data_all[skewed_feats] = np.log1p(data_all[skewed_feats])

#对非数值型数据进行one-hot转换
for i in object_columns[:-1]:
    data_all=data_all.join(pd.get_dummies(data_all[i]).add_prefix(i+"_"))
    data_all=data_all.drop(i,axis=1)
    
#查看缺失
data_all.isnull().sum().sort_values().tail(20)
data_all.isnull().sum().sort_values().tail(12).index

#缺失数据非常小的变量用众数填充
missvalue=['GarageCars', 'TotalBsmtSF', 'GarageArea','BsmtFinSF2', 
           'BsmtUnfSF', 'BsmtFullBath', 'BsmtHalfBath','BsmtFinSF1','MasVnrArea']

for i in missvalue:
    data_all[i].fillna(data_all[i].mode()[0],inplace=True)

data_all.MasVnrArea.fillna(data_all.MasVnrArea.mode()[0],inplace=True)

#缺失值较多的数据用机器学习进行预测填充

#创建XGarageYrBlt_train训练集，取有GarageYrBlt的数据
X_GarageYrBlt=data_all.loc[(data_all['GarageYrBlt'].notnull()),:]#提取非缺失的数据
X_GarageYrBlt=X_GarageYrBlt.drop(['GarageYrBlt','type','SalePrice','LotFrontage'],axis=1)
yGarageYrBlt_train=data_all.loc[data_all['GarageYrBlt'].notnull()==True,'GarageYrBlt']
print(X_GarageYrBlt.shape)
print(yGarageYrBlt_train.shape)

#创建XMasVnrArea_test测试集，取没有GarageYrBlt的数据
XGarageYrBlt_test=data_all.loc[data_all['GarageYrBlt'].isnull()==True,:]
XGarageYrBlt_test=XGarageYrBlt_test.drop(['GarageYrBlt','type','SalePrice','LotFrontage'],axis=1)
print(XGarageYrBlt_test.shape)

import xgboost as xgb
# 用Xgboost填充缺失值
def RFmodel(X_train,y_train,X_test):
    model_xgb= xgb.XGBRegressor(max_depth=5, colsample_btree=0.1, learning_rate=0.2, n_estimators=32, min_child_weight=2)
    model_xgb.fit(X_train,y_train)
    y_pre=model_xgb.predict(X_test)
    return y_pre

y_pred=RFmodel(X_GarageYrBlt,yGarageYrBlt_train,XGarageYrBlt_test)

#填充 GarageYrBlt缺失
data_all.loc[data_all['GarageYrBlt'].isnull(),'GarageYrBlt']=y_pred.astype(int)

#创建LotFrontage_train训练集，取有LotFrontage的数据
X_LotFrontage=data_all.loc[(data_all['LotFrontage'].notnull()),:]#提取非缺失的数据
X_LotFrontage=X_LotFrontage.drop(['GarageYrBlt','type','SalePrice','LotFrontage'],axis=1)
yLotFrontage_train=data_all.loc[data_all['LotFrontage'].notnull()==True,'LotFrontage']
print(X_LotFrontage.shape)
print(yLotFrontage_train.shape)

#创建LotFrontag_test测试集，取没有LotFrontage的数据
XLotFrontage_test=data_all.loc[data_all['LotFrontage'].isnull()==True,:]
XLotFrontage_test=XLotFrontage_test.drop(['GarageYrBlt','type','SalePrice','LotFrontage'],axis=1)
print(XLotFrontage_test.shape)

import xgboost as xgb
# 用Xgboost填充缺失值

y_pred=RFmodel(X_LotFrontage,yLotFrontage_train,XLotFrontage_test)

#填充LotFrontage缺失
data_all.loc[data_all['LotFrontage'].isnull(),'LotFrontage']=y_pred.astype(int)

#再次查看缺失
data_all.isnull().sum()


#创建训练集
data_all=data_all.drop(['type'],axis=1)

#将相关系数处理加载到流水线中 
#CustomCorrelationChooser 能够实现拟合逻辑和转换逻辑
from sklearn.base import TransformerMixin,BaseEstimator
class CustomCorrelationChooser(TransformerMixin,BaseEstimator):
    def __init__(self,response,cols_to_keep=[],threshold=None):
        self.response=response
        #保存响应变量
        self.threshold=threshold
        #保存阈值
        self.cols_to_keep=cols_to_keep 
        #初始化变量，并保存特征名
        
    def transform(self,X):
        return X[self.cols_to_keep] 
    #转换会选择合适的列
    
    def fit(self,X,*_):
        df=pd.concat([X,self.response],axis=1)
        self.cols_to_keep=df.columns[df.corr()[df.columns[-1]].abs()>self.threshold]
        self.cols_to_keep=[c for c in self.cols_to_keep if c in X.columns]
        return self

#对数据进行标准化处理
from sklearn.preprocessing import MinMaxScaler,StandardScaler
scaler = MinMaxScaler()
scaler2 = StandardScaler()

X=data_all.loc[0:1459,:]
X=X.drop(['SalePrice'],axis=1)
#Y=np.log1p(data_all.loc[0:1459,'SalePrice'])
Y=data_all.loc[0:1459,'SalePrice']

#特征选择
ccc = CustomCorrelationChooser(threshold=0,response=Y)
ccc.fit(X)
ccc.cols_to_keep
ccc.transform(X).head()

#特征扩充
from sklearn.preprocessing import PolynomialFeatures
poly= PolynomialFeatures(degree=2,include_bias=False,interaction_only=False)

#数据转换
X= scaler2.fit_transform(poly.fit_transform(ccc.transform(X)))
X_test=data_all.loc[1460:,:].drop(['SalePrice'],axis=1)[ccc.cols_to_keep]
X_test=scaler2.fit_transform(poly.fit_transform(X_test))

#分割训练集和验证集
from sklearn.model_selection import cross_val_score,train_test_split                                        
x_train, x_valid, y_train, y_valid =train_test_split(X,Y,train_size=0.8,random_state=10)

print(",训练数据特征:",X_train.shape,
      ",验证数据特征:",x_valid.shape,
     ",测试数据特征:",X_test.shape)
print(",训练数据标签:",y_train.shape,
     ',验证数据标签:',y_valid.shape)

#xgb建模
params = {
        'objective':'reg:linear',
        
        'n_estimators': 2000,
        'booster':'gbtree',
        'max_depth':11,
        'eval_metric':'mae',
        'learning_rate':0.01, 
        'min_child_weight':2,
        'subsample':0.8,
        'colsample_bytree':0.75,
        'seed':45,
        'reg_alpha':1e-06,
        'gamma':0,
        'nthread':-1,
        'n_jobs':1
}

d_train = xgb.DMatrix(x_train, label=y_train)
d_valid = xgb.DMatrix(x_valid, label=y_valid)
d_test = xgb.DMatrix(X_test)

watchlist = [(d_train, 'train'), (d_valid, 'valid')]

clf = xgb.train(params, d_train, 4000, watchlist, early_stopping_rounds=1500, maximize=False, verbose_eval=10)

p_test = clf.predict(d_test)
print(pd.DataFrame(np.expm1(p_test)).describe())

sub= pd.DataFrame()
sub['Id'] = data_test.Id
sub['SalePrice']=np.expm1(p_test)
sub.to_csv('house_price_xgb_priedict.csv', index=False)
